"""
Migrator (SQLite -> Firebase JSON)
–°–∫—Ä–∏–ø—Ç –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞ "–ó–æ–ª–æ—Ç–æ–π –ë–∞–∑—ã" –≤ —Ñ–æ—Ä–º–∞—Ç, –≥–æ—Ç–æ–≤—ã–π –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞ –≤ Firebase Realtime Database.

–ü–û–î–î–ï–†–ñ–ò–í–ê–ï–¢:
1. –§–∏–ª—å—Ç—Ä–∞—Ü–∏—é –º—É—Å–æ—Ä–∞ (—Ç–æ–ª—å–∫–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ —Å–ª–æ–≤–∞).
2. –ò–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω—ã–π —ç–∫—Å–ø–æ—Ä—Ç (—Ç–æ–ª—å–∫–æ –Ω–æ–≤—ã–µ/–∏–∑–º–µ–Ω–µ–Ω–Ω—ã–µ —Å–ª–æ–≤–∞).
"""

import sqlite3
import json
import os
import sys
from datetime import datetime
from collections import defaultdict

# ================= –ù–ê–°–¢–†–û–ô–ö–ò =================
DB_FILE = "czech_russian_dictionary.db"
OUTPUT_FILE = "firebase_update.json"

# –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–µ–π—Ç–∏–Ω–≥ –ø–µ—Ä–µ–≤–æ–¥–∞ (1 = –±—Ä–∞—Ç—å –≤—Å—ë, 3 = —Ç–æ–ª—å–∫–æ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ)
MIN_TRANSLATION_SCORE = 1 

# –î–ê–¢–ê –ü–û–°–õ–ï–î–ù–ï–ì–û –≠–ö–°–ü–û–†–¢–ê (YYYY-MM-DD)
# –û—Å—Ç–∞–≤—å—Ç–µ None, —á—Ç–æ–±—ã –≤—ã–≥—Ä—É–∑–∏—Ç—å –í–°–Æ –±–∞–∑—É (–ø–µ—Ä–µ–∑–∞–ø–∏—Å—å).
# –£–∫–∞–∂–∏—Ç–µ –¥–∞—Ç—É (–Ω–∞–ø—Ä–∏–º–µ—Ä, "2024-01-22"), —á—Ç–æ–±—ã –≤—ã–≥—Ä—É–∑–∏—Ç—å —Ç–æ–ª—å–∫–æ —Ç–æ, 
# —á—Ç–æ –∏–∑–º–µ–Ω–∏–ª–æ—Å—å –ü–û–°–õ–ï —ç—Ç–æ–π –¥–∞—Ç—ã (—Ä–µ–∂–∏–º –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è/–¥–æ–ø–æ–ª–Ω–µ–Ω–∏—è).
EXPORT_SINCE = None 
# –ü—Ä–∏–º–µ—Ä: EXPORT_SINCE = "2026-01-22"
# =============================================

def dict_factory(cursor, row):
    d = {}
    for idx, col in enumerate(cursor.description):
        d[col[0]] = row[idx]
    return d

class Migrator:
    def __init__(self, db_path):
        if not os.path.exists(db_path):
            print(f"‚ùå –û—à–∏–±–∫–∞: –§–∞–π–ª –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω: {db_path}")
            sys.exit(1)
            
        self.conn = sqlite3.connect(db_path)
        self.conn.row_factory = dict_factory
        self.cursor = self.conn.cursor()
        print(f"üîå –ü–æ–¥–∫–ª—é—á–µ–Ω–æ –∫ {db_path}")

    def fetch_translations_map(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –ø–µ—Ä–µ–≤–æ–¥—ã"""
        print("üì• –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–≤–æ–¥–æ–≤...")
        query = """
            SELECT t.czech_id, r.word, t.confidence_score
            FROM translations t
            JOIN russian_words r ON t.russian_id = r.id
            WHERE t.confidence_score >= ?
            ORDER BY t.confidence_score DESC
        """
        self.cursor.execute(query, (MIN_TRANSLATION_SCORE,))
        
        trans_map = defaultdict(list)
        for row in self.cursor.fetchall():
            trans_map[row['czech_id']].append(row['word'])
        return trans_map

    def fetch_forms_map(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å–ª–æ–≤–æ—Ñ–æ—Ä–º—ã"""
        print("üì• –ó–∞–≥—Ä—É–∑–∫–∞ —Å–ª–æ–≤–æ—Ñ–æ—Ä–º...")
        try:
            query = "SELECT base_form, inflected_form FROM word_forms"
            self.cursor.execute(query)
            
            forms_map = defaultdict(set)
            for row in self.cursor.fetchall():
                base = row['base_form'].lower().strip() if row['base_form'] else ""
                if base:
                    forms_map[base].add(row['inflected_form'])
            return forms_map
        except sqlite3.OperationalError:
            print("‚ö†Ô∏è –¢–∞–±–ª–∏—Ü–∞ word_forms –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –∏–ª–∏ –ø—É—Å—Ç–∞.")
            return {}

    def run(self):
        start_time = datetime.now()
        
        # 1. –ó–∞–≥—Ä—É–∑–∫–∞ –≤—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        translations = self.fetch_translations_map()
        forms_map = self.fetch_forms_map()
        
        print("üöÄ –ù–∞—á–∞–ª–æ —Å–±–æ—Ä–∫–∏ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞...")
        
        # 2. –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞ —Å —É—á–µ—Ç–æ–º —Ñ–∏–ª—å—Ç—Ä–æ–≤
        # –£–±—Ä–∞–ª–∏ 'WHERE is_processed = 1', —á—Ç–æ–±—ã –≤—ã–≥—Ä—É–∂–∞—Ç—å –í–°–ï —Å–ª–æ–≤–∞ —Å –ø–µ—Ä–µ–≤–æ–¥–∞–º–∏
        query = """
            SELECT id, word, word_normalized, gender, part_of_speech, stress, is_phrase, updated_at
            FROM czech_words
            WHERE 1=1
        """
        params = []

        # –§–∏–ª—å—Ç—Ä –ø–æ –¥–∞—Ç–µ (–ò–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω—ã–π —Ä–µ–∂–∏–º)
        if EXPORT_SINCE:
            print(f"üìÖ –†–ï–ñ–ò–ú –û–ë–ù–û–í–õ–ï–ù–ò–Ø: –í—ã–≥—Ä—É–∂–∞–µ–º —Å–ª–æ–≤–∞, –∏–∑–º–µ–Ω–µ–Ω–Ω—ã–µ –ø–æ—Å–ª–µ {EXPORT_SINCE}")
            query += " AND updated_at >= ?"
            params.append(EXPORT_SINCE)
        else:
            print("üì¶ –ü–û–õ–ù–´–ô –†–ï–ñ–ò–ú: –í—ã–≥—Ä—É–∂–∞–µ–º –≤—Å—é –±–∞–∑—É (–Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ DeepSeek)")

        self.cursor.execute(query, params)
        all_words = self.cursor.fetchall()
        
        if not all_words:
            print("‚ö†Ô∏è –ù–µ—Ç —Å–ª–æ–≤ –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏—Ö –∫—Ä–∏—Ç–µ—Ä–∏—è–º.")
            return

        total = len(all_words)
        print(f"üìä –ù–∞–π–¥–µ–Ω–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤: {total}")
        
        export_data = {}
        forms_index = {}  # –ù–û–í–´–ô –ò–ù–î–ï–ö–° –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞
        processed_count = 0
        skipped_count = 0

        for row in all_words:
            word_id = row['id']
            original_word = row['word']
            
            # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–ª—é—á–∞ Firebase
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ö–µ—à –∏–ª–∏ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ —Å–ª–æ–≤–æ –∫–∞–∫ –∫–ª—é—á
            if not row['word_normalized']:
                continue
                
            firebase_key = row['word_normalized'].lower().strip()
            # –û—á–∏—Å—Ç–∫–∞ –∫–ª—é—á–∞ –æ—Ç –∑–∞–ø—Ä–µ—â–µ–Ω–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤ Firebase
            for char in ['.', '#', '$', '[', ']', '/']:
                firebase_key = firebase_key.replace(char, '')
            
            if not firebase_key:
                continue

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –ø–µ—Ä–µ–≤–æ–¥–æ–≤ (–ü—É—Å—Ç—ã–µ —Å–ª–æ–≤–∞ –Ω–∞–º –Ω–µ –Ω—É–∂–Ω—ã)
            word_translations = translations.get(word_id, [])
            if not word_translations:
                skipped_count += 1
                continue

            # –°–±–æ—Ä —Ñ–æ—Ä–º
            word_forms = list(forms_map.get(firebase_key, []))
            if original_word not in word_forms:
                word_forms.insert(0, original_word)

            # –î–û–ë–ê–í–õ–Ø–ï–ú –í –ò–ù–î–ï–ö–°: –∫–∞–∂–¥–∞—è —Ñ–æ—Ä–º–∞ ‚Üí –±–∞–∑–æ–≤–æ–µ —Å–ª–æ–≤–æ
            for form in word_forms:
                form_normalized = form.lower().strip()
                # –û—á–∏—Å—Ç–∫–∞ –æ—Ç –∑–∞–ø—Ä–µ—â–µ–Ω–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤
                for char in ['.', '#', '$', '[', ']', '/']:
                    form_normalized = form_normalized.replace(char, '')
                if form_normalized and form_normalized != firebase_key:
                    forms_index[form_normalized] = firebase_key

            # –°—Ç—Ä—É–∫—Ç—É—Ä–∞ JSON –æ–±—ä–µ–∫—Ç–∞
            word_obj = {
                "word": original_word,
                "word_normalized": row['word_normalized'],
                "translations": word_translations[:10],
                "gender": row['gender'] or "",
                "grammar": row['part_of_speech'] or "",
                "stress": row['stress'] or "",
                "forms": word_forms[:20],
                "is_phrase": bool(row['is_phrase']),
                "source": "golden_db",
                "last_updated": row['updated_at'] or datetime.now().isoformat(),
                "examples": [] 
            }
            
            export_data[firebase_key] = word_obj
            processed_count += 1
            
            if processed_count % 5000 == 0:
                print(f"   ... –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ {processed_count}/{total}")

        # 3. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
        print(f"üíæ –ó–∞–ø–∏—Å—å –≤ —Ñ–∞–π–ª {OUTPUT_FILE}...")
        print(f"   üìä –ò–Ω–¥–µ–∫—Å —Å–ª–æ–≤–æ—Ñ–æ—Ä–º: {len(forms_index)} –∑–∞–ø–∏—Å–µ–π")

        try:
            # –°–æ–∑–¥–∞—ë–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Å –∏–Ω–¥–µ–∫—Å–æ–º
            final_structure = {
                "dictionary": export_data,
                "forms_index": forms_index
            }

            with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
                json.dump(final_structure, f, ensure_ascii=False) # minified

            file_size_mb = os.path.getsize(OUTPUT_FILE) / (1024 * 1024)

            print(f"\n‚úÖ –ì–û–¢–û–í–û!")
            print(f"   üìÇ –§–∞–π–ª: {OUTPUT_FILE}")
            print(f"   üì¶ –°–ª–æ–≤ –≤ —Å–ª–æ–≤–∞—Ä–µ: {processed_count}")
            print(f"   üîç –§–æ—Ä–º –≤ –∏–Ω–¥–µ–∫—Å–µ: {len(forms_index)}")
            print(f"   ‚öñÔ∏è –†–∞–∑–º–µ—Ä: {file_size_mb:.2f} MB")

            print("\nüìã –ò–ù–°–¢–†–£–ö–¶–ò–Ø –ü–û –ó–ê–ì–†–£–ó–ö–ï –í FIREBASE:")
            if EXPORT_SINCE:
                print("   –¢.–∫. —ç—Ç–æ –ß–ê–°–¢–ò–ß–ù–û–ï –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ, –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–æ–º–∞–Ω–¥—É UPDATE:")
                print(f"   üëâ firebase database:update / {OUTPUT_FILE}")
            else:
                print("   –¢.–∫. —ç—Ç–æ –ü–û–õ–ù–ê–Ø –±–∞–∑–∞, –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ Import JSON –≤ Firebase Console")
                print(f"   –∏–ª–∏ –∫–æ–º–∞–Ω–¥—É: firebase database:set / {OUTPUT_FILE}")
                print("\n   ‚ö†Ô∏è –í–ù–ò–ú–ê–ù–ò–ï: –≠—Ç–æ –ü–ï–†–ï–ó–ê–ü–ò–®–ï–¢ –≤—Å—é –±–∞–∑—É!")
                
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø–∏—Å–∏: {e}")

    def __del__(self):
        if hasattr(self, 'conn'):
            self.conn.close()

if __name__ == "__main__":
    migrator = Migrator(DB_FILE)
    migrator.run()